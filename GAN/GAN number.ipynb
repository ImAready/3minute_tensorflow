{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 9.2 원하는 숫자 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\data\\mnist\\data\\train-images-idx3-ubyte.gz\n",
      "Extracting ..\\data\\mnist\\data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ..\\data\\mnist\\data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ..\\data\\mnist\\data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"..\\data\\mnist\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# 옵션 설정\n",
    "###########\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10\n",
    "\n",
    "\n",
    "##############\n",
    "# 신경망 모델 구성\n",
    "#############\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈에 레이블 데이터를 힌트로 넣어줌. \n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "\n",
    "# 생성자 신경망 구성\n",
    "# 학습 시 각 신경망의 변수들을 따로 학습시킨다.\n",
    "def generator(noise, labels):\n",
    "    # tf.layers 사용 -> scope 지정 : scope에 해당하는 변수들만 불러올 수 있다.\n",
    "    with tf.variable_scope('generator'):\n",
    "        #concat 함수 : noise값에 labels 정보를 추가\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "        # 은닉층 생성\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                activation = tf.nn.relu)\n",
    "        # 출력층 구성\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                activation = tf.nn.sigmoid)\n",
    "    return output\n",
    "\n",
    "\n",
    "        \n",
    "# 구분자 신경망 구성\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    # 진짜 이미지를 판별할 때와 가짜 이미지를 판별할때 똑같은 변수 사용해야함.\n",
    "    # scope.reuse_variables 함수로 이전에 사용한 변수 재사용\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                activation = tf.nn.relu)\n",
    "        # 손실값에 sigmoid_entropy 함수 사용하기 위해 활성화함수 안씀\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                activation = None)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# 무작위 노이즈 생성 함수\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(-1., 1., size=(batch_size, n_noise))\n",
    "\n",
    "\n",
    "\n",
    "# 레이블 정보 추가 -> 레이블에 해당하는 이미지 생성 유도\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "# 가짜 이미지 구분자 -> 진짜 이미지 구분에 사용한 변수 사용하도록 reuse=True\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########\n",
    "# 손실함수\n",
    "###########\n",
    "# D_real : 1에 가깝게, 실제 이미지는 진짜라고 판별\n",
    "# D_gene : 0에 가깝게, 가짜 이미지는 가짜라고 판별\n",
    "# sigmoid_cross_entropy_with_logits 함수 사용\n",
    "\n",
    "loss_D_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            # ones_like : D_real 결과값과 D_real 크기만큼 1로 채운 값들을 비교\n",
    "            logits=D_real, labels=tf.ones_like(D_real)))\n",
    "\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# 이 값을 최소화하면 구분자(경찰)을 학습시킬 수 있다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "\n",
    "\n",
    "\n",
    "# loss_G ㅣ 생성자 학습시키기 위한 손실값\n",
    "loss_G = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ac6f3e215278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         _, loss_val_D = sess.run([train_D, loss_D],\n\u001b[1;32m---> 35\u001b[1;33m                                 feed_dict={X: batch_xs, Y:batch_ys, Z: noise})\n\u001b[0m\u001b[0;32m     36\u001b[0m         _, loss_val_G = sess.run([train_G, loss_G],\n\u001b[0;32m     37\u001b[0m                                 feed_dict={Y: batch_ys, Z: noise})\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "\n",
    "# discriminator, generator 스코프에서 사용된 변수들을 가져온 뒤\n",
    "# 이 변수들을 최적화할 각 손실함수와 함께 최적화 함수에 넣어\n",
    "# 학습 모델 구성 완료\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                          scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                          scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                           var_list = vars_D)\n",
    "\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                           var_list = vars_G)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "# 학습 진행\n",
    "###########\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        \n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                feed_dict={X: batch_xs, Y:batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                feed_dict={Y: batch_ys, Z: noise})\n",
    "    print('Epoch::','%04d' % epoch,\n",
    "         'D loss:: {:.4}'.format(loss_val_D),\n",
    "         'G loss:: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "\n",
    "    #############\n",
    "    # 결과 확인 (for문 안에서)\n",
    "    # 0, 9, 19, 29..마다 생성기로 이미지를 생성하여 확인\n",
    "    ############\n",
    "\n",
    "    # 노이즈를 만들고 생성자 G에 넣어 결과값을 만든다.\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Y:mnist.test.labels[:sample_size],\n",
    "                                         Z: noise})\n",
    "\n",
    "\n",
    "    # 노이즈 결과값을 28*28 크기의 가짜 이미지로 만들고\n",
    "    fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "    \n",
    "    # 위 : 진짜 이미지, 아래 : 생성한 이미지\n",
    "    for i in range(sample_size):\n",
    "        ax[0][i].set_axis_off()\n",
    "        ax[1][i].set_axis_off()\n",
    "        \n",
    "        ax[0][i].imshow(np.reshape(mnist.test.images[i], (28,28)))\n",
    "        ax[1][i].imshow(np.reshape(samples[i], (28,28)))\n",
    "    # samples 폴더에 저장\n",
    "    plt.savefig('samples2\\{}.png'.format(str(epoch).zfill(3),\n",
    "                                       bbox_inches='tight'))\n",
    "\n",
    "    plt.close(fig)\n",
    "    \n",
    "print('최적화완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
