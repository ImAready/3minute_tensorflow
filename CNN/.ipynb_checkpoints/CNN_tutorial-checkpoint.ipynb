{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7. CNN (합성곱 신경망)\n",
    "\n",
    "이미지 인식 분야에 많이 사용. 최근 음성인식, 자연어 처리 등에도 사용.  \n",
    "\n",
    "#### 7.1 CNN 개념\n",
    "\n",
    "![CNN구조](./img/img1.JPG)\n",
    "\n",
    "**컨볼루션 계층(합성곱 계층)**  \n",
    "- (2D 컨볼루션의 경우) 2차원 평면 행렬에서 지정한 영역 값들을 하나의 값으로 압축하는 것. *압축할 때 가중치와 1개의 편향을 적용한다.* 예를들어 윈도우 크기가 3X3이라면, 3X3개의 가중치와 1개의 편향이 필요하다. 각각을 **커널**또는 **필터**라고 하며 은닉층을  만들기 위한 모든 윈도우에 공통적으로 적용된다.  \n",
    "\n",
    "- 28X28 예\n",
    "    - 기본 신경망 : 784개 가중치를 찾아야 한다.\n",
    "    - CNN : 9개 가중치를 찾아야 한다. (윈도우 크기 만큼)  \n",
    "\n",
    "**풀링 계층**\n",
    "- (2D 컨볼루션의 경우) 2차원 평면 행렬에서 지정한 영역 값들을 하나의 값으로 압축하는 것. *압축할 때 값들 중 하나를 선택해서 가져온다.*\n",
    "\n",
    "![컨볼루션,풀링계층](./img/img2.JPG)\n",
    "\n",
    "이 계층들을 얼마나 많이, 어떤 방식으로 쌓느냐에 따라 성능차이와 풀 수 있는 문제가 달라진다.  \n",
    "\n",
    "위 그림과 같이 지정한 크기의 영역을 **윈도우**라고 하고, 이 윈도우의 값을 오른쪽 -> 아래쪽으로 한 칸씩 움직이면서 은닉층을 완성한다.  \n",
    "\n",
    "움직이는 크기는 변경가능하며, 이동할 칸의 개수 값을 **스크라이드**라고 한다.  \n",
    "\n",
    "![스트라이드](./img/img3.JPG)\n",
    "\n",
    "\n",
    "보통 여러개의 커널을 사용하는데, 커널의 크기나 개수는 하이퍼파라미터로 정하는 일이 매우 중요하다.\n",
    "\n",
    "![다중커널](./img/img4.JPG)\n",
    "\n",
    "\n",
    "#### 7.2 모델 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\\mnist\\data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예 28X28 입력\n",
    "# CNN 모델은 2차원 평면으로 구성.\n",
    "# X = [입력 데이터 개수, 28, 28, 특징 개수(mnist는 채널 색상이 한 개)]\n",
    "# Y = [입력 데이터 개수, 출력 분류]\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32,[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "################\n",
    "# 첫 번째 CNN계층\n",
    "################\n",
    "# 1. 3X3 크기의 커널을 가진 컨볼루션 계층 생성\n",
    "# tf.nn.conv2d 함수 사용\n",
    "# 입력층 X, 첫 번째 층 가중치 W1, 오른쪽 1칸, 아래쪽 1칸씩 움직이는 32개의 커널을 가짐.\n",
    "# padding='SAME' 커널 슬라이딩 시 이미지의 가장 외곽에서 한 칸 밖으로 움직이는 옵션\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')  \n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "\n",
    "# 2. 풀링 계층 생성\n",
    "# 컨볼루션 계층을 입력으로 커널 크기를 2X2로 하는 계층을 만든다.\n",
    "# strides=[1,2,2,1] : 슬라이딩 시 2칸씩 이동 옵션.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]\n",
    "                   , padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "위 코드 결과 첫 번째 CNN 계층 구성은 아래와 같음.  \n",
    "![CNN 첫번째 계층](./img/img5.JPG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# 두 번째 CNN 계층\n",
    "##################\n",
    "\n",
    "# 3X3 크기의 커널 64개로 구성된 컨볼루션 계층\n",
    "# [3, 3, 첫 번째 컨볼루션 계층 커널 개수(출력개수, 첫 번째 컨볼루션 계층이 찾아낸 특징개수, 64]\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "# 2X2 크기의 풀링 계층\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]\n",
    "                   , padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![두 번째 계층 구조](./img/img6.JPG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 추출한 특징을 이용해 10개의 분유를 만들어내는 계층 생성\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64 ])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 10개의 분류는 1차원으로 차원을 줄인다. 직전 풀링 계층 크기가 7*7*64 이므로 tf.reshape()함수로 7*7*64 크기의 1차원 계층으로 만든다.\n",
    "2. 최종 출력값의 중간 단계인 256개의 뉴런으로 연결하는 신경망을 만들어 둔다. **인접 계층의 모든 뉴런과 상호 연결된 계층을 *완전 연결 계층*이라고 한다.**\n",
    "3. 과적합을 막아줄 드롭아웃 기법을 적용한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  0.341\n",
      "Epoch: 0002 Avg. cost =  0.110\n",
      "Epoch: 0003 Avg. cost =  0.077\n",
      "Epoch: 0004 Avg. cost =  0.061\n",
      "Epoch: 0005 Avg. cost =  0.052\n",
      "Epoch: 0006 Avg. cost =  0.042\n",
      "Epoch: 0007 Avg. cost =  0.036\n",
      "Epoch: 0008 Avg. cost =  0.032\n",
      "Epoch: 0009 Avg. cost =  0.030\n",
      "Epoch: 0010 Avg. cost =  0.025\n",
      "Epoch: 0011 Avg. cost =  0.023\n",
      "Epoch: 0012 Avg. cost =  0.020\n",
      "Epoch: 0013 Avg. cost =  0.019\n",
      "Epoch: 0014 Avg. cost =  0.018\n",
      "Epoch: 0015 Avg. cost =  0.015\n",
      "최적화 완료!!\n",
      "정확도: 0.9896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# L3의 256개의 출력값을 받아 \n",
    "# 최종 출력값인 0 ~ 9 레이블을 갖는 10개의 출력값을 만든다.\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)\n",
    "\n",
    "# 손실 함수\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=model, labels=Y))\n",
    "# 최적화 함수\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "#optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "\n",
    "#############\n",
    "# 신경망 학습\n",
    "#############\n",
    "# 입력값 28*28 형태로 아래와 같은 재구성 필요\n",
    "# batch_xs.reshape(-1, 28, 28, 1)\n",
    "# mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 학습\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict={X: batch_xs,\n",
    "                                        Y: batch_ys,\n",
    "                                        keep_prob: 0.7})\n",
    "        total_cost += cost_val\n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "         'Avg. cost = ','{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!!')\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                      feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                Y : mnist.test.labels,\n",
    "                                keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 7.3 고수준 API\n",
    " 텐서플로에서 제공하는 layer 모듈을 이용해 위 CNN 모델을 좀 더 간단하게 만든다. \n",
    " cnn.ipynb 파일\n",
    " \n",
    "#### 7.4 더보기\n",
    "실제 문제를 풀려면 더 많은 컴퓨터 자원이 필요한데 수슬이 제공하는 Cloud ML을 이용하면 편하게 학습시킬 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
